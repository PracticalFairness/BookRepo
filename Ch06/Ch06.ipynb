{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from aif360.datasets import CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_compas\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "## Equalized odds post-processing \n",
    "# Odds equalizing post-processing algorithm\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "\n",
    "## Calbirating equalized odds post-processing\n",
    "from aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data set\n",
    "### p 159"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_data  = load_preproc_data_compas()\n",
    "priv_group   = [{'race': 1}]\n",
    "unpriv_group = [{'race': 0}]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compas_data = load_preproc_data_compas()\n",
    "compas_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide dataset into train, validation, and test partitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(132)\n",
    "def split_data_trn_vld_tst(data_raw):\n",
    "    dset_raw_trn, dset_raw_vt  = data_raw.split([0.7], \n",
    "                                               shuffle = True)\n",
    "    dset_raw_vld, dset_raw_tst = dset_raw_vt.split([0.5], \n",
    "                                                   shuffle = True)\n",
    "    \n",
    "    return dset_raw_trn, dset_raw_vld, dset_raw_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_raw_trn, dset_raw_vld, dset_raw_tst = split_data_trn_vld_tst(compas_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metric for the original datasets (without any classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## p 161\n",
    "metric_orig_test = BinaryLabelDatasetMetric(dset_raw_tst, \n",
    "                             unprivileged_groups = unpriv_group,\n",
    "                             privileged_groups   = priv_group)\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % \n",
    "      metric_orig_test.mean_difference()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier (logistic regression) on original training data\n",
    "### not shown in book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "dataset_orig_train_pred = dset_raw_trn.copy(deepcopy = True)\n",
    "dataset_orig_valid_pred = dset_raw_vld.copy(deepcopy = True)\n",
    "dataset_orig_test_pred  = dset_raw_tst.copy(deepcopy = True)\n",
    "\n",
    "# Logistic regression classifier and predictions for training data\n",
    "scale_orig = StandardScaler()\n",
    "X_train = scale_orig.fit_transform(dset_raw_trn.features)\n",
    "y_train = dset_raw_trn.labels.ravel()\n",
    "lmod = LogisticRegression()\n",
    "lmod.fit(X_train, y_train)\n",
    "\n",
    "fav_idx = np.where(lmod.classes_ == dset_raw_trn.favorable_label)[0][0]\n",
    "y_train_pred_prob = lmod.predict_proba(X_train)[:,fav_idx]\n",
    "\n",
    "# Prediction probs for validation and testing data\n",
    "X_valid = scale_orig.transform(dset_raw_vld.features)\n",
    "y_valid_pred_prob = lmod.predict_proba(X_valid)[:,fav_idx]\n",
    "\n",
    "X_test = scale_orig.transform(dset_raw_tst.features)\n",
    "y_test_pred_prob = lmod.predict_proba(X_test)[:,fav_idx]\n",
    "\n",
    "class_thresh = 0.5\n",
    "dataset_orig_train_pred.scores = y_train_pred_prob.reshape(-1,1)\n",
    "dataset_orig_valid_pred.scores = y_valid_pred_prob.reshape(-1,1)\n",
    "dataset_orig_test_pred.scores = y_test_pred_prob.reshape(-1,1)\n",
    "\n",
    "y_train_pred = np.zeros_like(dataset_orig_train_pred.labels)\n",
    "y_train_pred[y_train_pred_prob >= class_thresh] = dataset_orig_train_pred.favorable_label\n",
    "y_train_pred[~(y_train_pred_prob >= class_thresh)] = dataset_orig_train_pred.unfavorable_label\n",
    "dataset_orig_train_pred.labels = y_train_pred\n",
    "\n",
    "y_valid_pred = np.zeros_like(dataset_orig_valid_pred.labels)\n",
    "y_valid_pred[y_valid_pred_prob >= class_thresh] = dataset_orig_valid_pred.favorable_label\n",
    "y_valid_pred[~(y_valid_pred_prob >= class_thresh)] = dataset_orig_valid_pred.unfavorable_label\n",
    "dataset_orig_valid_pred.labels = y_valid_pred\n",
    "    \n",
    "y_test_pred = np.zeros_like(dataset_orig_test_pred.labels)\n",
    "y_test_pred[y_test_pred_prob >= class_thresh] = dataset_orig_test_pred.favorable_label\n",
    "y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_orig_test_pred.unfavorable_label\n",
    "dataset_orig_test_pred.labels = y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results before post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_classifier_metric = ClassificationMetric(dset_raw_tst, \n",
    "                                               dataset_orig_test_pred,\n",
    "                                               unprivileged_groups = unpriv_group,\n",
    "                                               privileged_groups   = priv_group)\n",
    "\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(logit_classifier_metric.difference(logit_classifier_metric.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(logit_classifier_metric.difference(logit_classifier_metric.generalized_false_negative_rate))\n",
    "print(\"Mean difference in outcomes\")\n",
    "print(logit_classifier_metric.mean_difference()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that logistic regression produces far more disparate outcome than what is found in raw data outcome!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Equality of Odds post-processing\n",
    "### p 161"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 94\n",
    "\n",
    "# Learn parameters to equalize odds and apply to create a new dataset\n",
    "eop = EqOddsPostprocessing(unprivileged_groups = unpriv_group, \n",
    "                           privileged_groups   = priv_group, \n",
    "                           seed                = SEED)\n",
    "eop = eop.fit(dset_raw_vld, dataset_orig_valid_pred)\n",
    "\n",
    "eop_trn_pred = eop.predict(dataset_orig_train_pred)\n",
    "\n",
    "eop_trn_metric = ClassificationMetric(dset_raw_trn, eop_trn_pred,\n",
    "                             unprivileged_groups = unpriv_group,\n",
    "                             privileged_groups  = priv_group)\n",
    "\n",
    "print(\"TRAINING DATA\")\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(eop_trn_metric.difference(eop_trn_metric.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(eop_trn_metric.difference(eop_trn_metric.generalized_false_negative_rate))\n",
    "print(\"Mean difference in outcomes\")\n",
    "print(eop_trn_metric.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eop_test_pred = eop.predict(dataset_orig_test_pred)\n",
    "eop_test_metric = ClassificationMetric(dset_raw_tst, eop_test_pred,\n",
    "                             unprivileged_groups = unpriv_group,\n",
    "                             privileged_groups   = priv_group)\n",
    "print(\"TEST DATA\")\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(eop_test_metric.difference(eop_test_metric.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(eop_test_metric.difference(eop_test_metric.generalized_false_negative_rate))\n",
    "print(\"Mean difference in outcomes\")\n",
    "print(eop_test_metric.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration preserving equalized odds\n",
    "### p 166"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## p 166\n",
    "\n",
    "# Learn parameters to equalize odds and apply to create a new dataset\n",
    "cpp = CalibratedEqOddsPostprocessing(privileged_groups   = priv_group,\n",
    "                                     unprivileged_groups = unpriv_group,\n",
    "                                     cost_constraint     = 'fpr',\n",
    "                                     seed                = 76)\n",
    "cpp = cpp.fit(dset_raw_vld, dataset_orig_valid_pred)\n",
    "\n",
    "\n",
    "dataset_transf_test_pred = cpp.predict(dataset_orig_test_pred)\n",
    "cm_transf_test_metric = ClassificationMetric(dset_raw_tst, dataset_transf_test_pred,\n",
    "                             unprivileged_groups = unpriv_group,\n",
    "                             privileged_groups   = priv_group)\n",
    "\n",
    "\n",
    "dataset_transf_train_pred = cpp.predict(dataset_orig_train_pred)\n",
    "cm_transf_train_metric = ClassificationMetric(dset_raw_trn, dataset_transf_train_pred,\n",
    "                             unprivileged_groups = unpriv_group,\n",
    "                             privileged_groups   = priv_group)\n",
    "\n",
    "print(\"CALIBRATING EQUALIZED ODDS PERFORMANCE ON TRAIN DATA\")\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_transf_train_metric.difference(cm_transf_train_metric.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_transf_train_metric.difference(cm_transf_train_metric.generalized_false_negative_rate))\n",
    "print(\"Mean difference in outcomes\")\n",
    "print(cm_transf_train_metric.mean_difference())\n",
    "print(\"\")\n",
    "print(\"CALIBRATING EQUALIZED ODDS PERFORMANCE ON TEST DATA\")\n",
    "print(\"Difference in GFPR between unprivileged and privileged groups\")\n",
    "print(cm_transf_test_metric.difference(cm_transf_test_metric.generalized_false_positive_rate))\n",
    "print(\"Difference in GFNR between unprivileged and privileged groups\")\n",
    "print(cm_transf_test_metric.difference(cm_transf_test_metric.generalized_false_negative_rate))\n",
    "print(\"Mean difference in outcomes\")\n",
    "print(cm_transf_test_metric.mean_difference())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
