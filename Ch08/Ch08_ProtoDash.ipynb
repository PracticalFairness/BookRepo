{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "\n",
    "from aif360.datasets import MEPSDataset19\n",
    "\n",
    "import aix360\n",
    "from aix360.algorithms.protodash import ProtodashExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_data19 = MEPSDataset19()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    med_data19.features, med_data19.labels, \n",
    "    random_state = 0, stratify = med_data19.labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "med_data19.label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train         = pd.DataFrame(X_train)\n",
    "X_train.columns = med_data19.feature_names\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(X_test)\n",
    "X_test.columns = med_data19.feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ProtoDash\n",
    "### p 229"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preparing the data p 230"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## p 230\n",
    "X_scale = np.vstack((X_train, X_test))\n",
    "Xmax    = np.max(X_scale, axis = 0)\n",
    "Xmin    = np.min(X_scale, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale = (X_scale - Xmin)/(Xmax - Xmin)\n",
    "X_scale = X_scale - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scale_train = X_scale[:X_train.shape[0]]\n",
    "X_scale_test  = X_scale[X_train.shape[0]:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## p 230\n",
    "rf = RFC(n_estimators=200, max_depth = 4)\n",
    "rf.fit(X_scale_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train accuracy: %0.2f      Test accuracy: %0.2f' % \n",
    "          (accuracy_score(y_train, rf.predict(X_scale_train)),\n",
    "          accuracy_score(y_test, rf.predict(X_scale_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate samples similar to a specific data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## p 231\n",
    "\n",
    "## predict values from our model to divide data points according to predicted values\n",
    "predicted_vals = rf.predict(X_scale_test)\n",
    "results_df = pd.DataFrame(np.hstack([X_scale_test, predicted_vals.reshape(-1, 1)]))\n",
    "results_df.columns = list(X_test.columns.values) + [\"Class\"]\n",
    "\n",
    "## looking at those with UTILIZATION == 0.0 (as a binary variable of 0 or 1)\n",
    "base_dataset = results_df[results_df.Class == 0.0].values\n",
    "\n",
    "## select an example to explain \n",
    "selected_example_idx = 5\n",
    "data_to_explain = np.expand_dims(base_dataset[selected_example_idx], axis = 1).transpose()\n",
    "\n",
    "## remove the example of interest from the base dataset\n",
    "base_dataset = np.delete(base_dataset, selected_example_idx, 0)\n",
    "\n",
    "## how many prototypes do we want returned?\n",
    "num_prototypes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## p 231\n",
    "exp = ProtodashExplainer()\n",
    "(W, S, _) = exp.explain(data_to_explain, base_dataset, m = num_prototypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## p 232\n",
    "dfs                     = pd.DataFrame.from_records(results_df.iloc[S, 0:-1].astype('double'))\n",
    "dfs.columns             = X_test.columns\n",
    "dfs[138]                = 0\n",
    "dfs.columns.values[138] = \"Utilization\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[\"Weight\"] = np.around(W, 4)/np.sum(np.around(W, 4)) # Calculate normalized importance weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_row = pd.DataFrame(data_to_explain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_row[139] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_row.columns = dfs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = dfs.append(x_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## p 232\n",
    "## reorder with Weight\n",
    "dfs.sort_values(\"Weight\", inplace = True, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.transpose().to_csv( \"protodash_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs.transpose()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
